import os
import sys
import time

#
# we assume everwhere our current directory is in the package 
# test area, so go ahead and cd there
#
os.chdir(os.path.dirname(__file__))


#
# import modules we need to test, since we chdir()ed, can use relative path
#
sys.path.append("../lib")
import creds
import condor

class TestCondorUnit:
    """
        Use with pytest... unit tests for ../lib/*.py
    """

    def get_submit_file():
        filename="/tmp/tst{0}.sub".format(os.getpid())
        f = open(filename, "w")
        f.write("""
# generated by jobsub_lite 
# 
universe           = vanilla
executable         = /bin/true
arguments          = 

output             = lookaround.xx.$(Cluster).$(Process).out
error              = lookaround.xx.$(Cluster).$(Process).err
log                = lookaround.xx.$(Cluster).$(Process).log
environment        = CLUSTER=$(Cluster);PROCESS=$(Process);CONDOR_TMP=;BEARER_TOKEN_FILE=.condor_creds/{group}.use;CONDOR_EXEC=/tmp;DAGMANJOBID=$(DAGManJobId);GRID_USER={user};JOBSUBJOBID=$(CLUSTER).$(PROCESS)@jobsubdevgpvm01.fnal.gov;EXPERIMENT={group};SAM_EXPERIMENT=samdev
rank               = Mips / 2 + Memory
job_lease_duration = 3600
notification       = Never
transfer_output    = True
transfer_error     = True
transfer_executable= True
when_to_transfer_output = ON_EXIT_OR_EVICT
transfer_output_files = .empty_file
request_memory = 2048.0
request_disk = 102400.0KB
+JobsubClientDN=""
+JobsubClientIpAddress="131.225.67.71"
+Owner="{user}"
+JobsubServerVersion="lite_v1_0"
+JobsubClientVersion="lite_v1_0"
+JobsubClientKerberosPrincipal=""
+JOB_EXPECTED_MAX_LIFETIME = 28800.0
notify_user = {user}@fnal.gov
+AccountingGroup = "group_{group}.{user}"
+Jobsub_Group="{group}"
+JobsubJobId="$(CLUSTER).$(PROCESS)@jobsubdevgpvm01.fnal.gov"
+Drain = False
+GeneratedBy =" jobsubdevgpvm01.fnal.gov"

+DESIRED_usage_model="OPPORTUNISTIC,DEDICATED"

requirements  = target.machine =!= MachineAttrMachine1 && target.machine =!= MachineAttrMachine2  && (isUndefined(DesiredOS) || stringListsIntersect(toUpper(DesiredOS),IFOS_installed)) && (stringListsIntersect(toUpper(target.HAS_usage_model, toUpper(my.DESIRED_usage_model))))

#
# this is supposed to get us output even if jobs are held(?)
#
+SpoolOnEvict = false
#
#
#
use_oauth_services = {group}

queue 1
        """.format( user = os.environ["USER"], group = TestUnit.test_group ))
        f.close()
        return filename

    def get_dag_file():
        filename="/tmp/tst{0}.dag".format(os.getpid())
        f = open(filename, "w")
        f.write("""
        """)
        f.close()
        return filename

    # lib/condor.py routines...

    def test_get_schedd_1(self):
        schedd =  condor.get_schedd(TestUnit.test_vargs)
        print("got schedd: {0}".format(schedd))
        print("schedd name: {0}".format(schedd['Name']))
        assert schedd['Name'] == TestUnit.test_schedd

    def test_load_submit_file_1(self):
        res = condor.load_submit_file(TestUnit.get_submit_file())
        assert str(res[0]).find('universe = vanilla') >= 0
        assert str(res[0]).find('executable = /bin/true') >= 0

    def test_submit_1(self):
        # to actually submit we do need creds, and our group set...
        os.environ["GROUP"] = TestUnit.test_group
        creds.get_creds()

        res = condor.submit(TestUnit.get_submit_file(), TestUnit.test_vargs, TestUnit.test_schedd )
        print("got: " , res)
        assert res

    def x_test_submit_dag_1(self):
        # XXX fix me
        res = condor.submit_dag(TestUnit.get_dag_file(), TestUnit.test_vargs, TestUnit.test_schedd, cmd_args=[])
