import sys
sys.path.append("../lib")

import os

import condor
import creds

class TestCondor:
    """
        Use with pytest... unit tests for ../lib/condor.py
    """

    test_schedd = "jobsubdevgpvm01.fnal.gov"
    test_vargs = { 
            "devserver":          True,
            "environment":       "SAM_EXPERIMENT",
            "group":             "fermilab",
            "resource-provides": "usage_model=OPPORTUNISTIC,DEDICATED,OFFSITE" 
        }

    def get_submit_file():
        filename="/tmp/tst{0}.sub".format(os.getpid())
        f = open(filename, "w")
        f.write("""
# generated by jobsub_lite 
# 
universe           = vanilla
executable         = /bin/true
arguments          = 

output             = lookaround.xx.$(Cluster).$(Process).out
error              = lookaround.xx.$(Cluster).$(Process).err
log                = lookaround.xx.$(Cluster).$(Process).log
environment        = CLUSTER=$(Cluster);PROCESS=$(Process);CONDOR_TMP=;BEARER_TOKEN_FILE=.condor_creds/fermilab.use;CONDOR_EXEC=/tmp;DAGMANJOBID=$(DAGManJobId);
GRID_USER={user};JOBSUBJOBID=$(CLUSTER).$(PROCESS)@jobsubdevgpvm01.fnal.gov;EXPERIMENT=fermilab;SAM_EXPERIMENT=samdev
rank               = Mips / 2 + Memory
job_lease_duration = 3600
notification       = Never
transfer_output    = True
transfer_error     = True
transfer_executable= True
when_to_transfer_output = ON_EXIT_OR_EVICT
transfer_output_files = .empty_file
request_memory = 2048.0
request_disk = 102400.0KB
+JobsubClientDN=""
+JobsubClientIpAddress="131.225.67.71"
+Owner="{user}"
+JobsubServerVersion="lite_v1_0"
+JobsubClientVersion="lite_v1_0"
+JobsubClientKerberosPrincipal=""
+JOB_EXPECTED_MAX_LIFETIME = 28800.0
notify_user = {user}@fnal.gov
+AccountingGroup = "group_fermilab.{user}"
+Jobsub_Group="fermilab"
+JobsubJobId="$(CLUSTER).$(PROCESS)@jobsubdevgpvm01.fnal.gov"
+Drain = False
+GeneratedBy =" jobsubdevgpvm01.fnal.gov"

+DESIRED_usage_model="OPPORTUNISTIC,DEDICATED"

requirements  = target.machine =!= MachineAttrMachine1 && target.machine =!= MachineAttrMachine2  && (isUndefined(DesiredOS) || stringListsIntersect(toUpper(DesiredOS),IFOS_installed)) && (stringListsIntersect(toUpper(target.HAS_usage_model, toUpper(my.DESIRED_usage_model)))

#
# this is supposed to get us output even if jobs are held(?)
#
+SpoolOnEvict = false
#
#
#
use_oauth_services = fermilab

queue 1
        """.format( user = os.environ["USER"]))
        f.close()
        return filename

    def get_dag_file():
        filename="/tmp/tst{0}.dag".format(os.getpid())
        f = open(filename, "w")
        f.write("""
        """)
        f.close()
        return filename

    def test_get_schedd_1(self):
        schedd =  condor.get_schedd(TestCondor.test_vargs)
        print("got schedd: {0}".format(schedd))
        print("schedd name: {0}".format(schedd['Name']))
        assert schedd['Name'] == TestCondor.test_schedd

    def test_load_submit_file_1(self):
        res = condor.load_submit_file(TestCondor.get_submit_file())
        assert str(res[0]).find('universe = vanilla') >= 0
        assert str(res[0]).find('executable = /bin/true') >= 0

    def test_submit_1(self):
        # to actually submit we do need creds, and our group set...
        os.environ["GROUP"] = 'fermilab'
        creds.get_creds()

        res = condor.submit(TestCondor.get_submit_file(), TestCondor.test_vargs, TestCondor.test_schedd )
        print("got: " , res)
        assert res

    def x_test_submit_dag_1(self):
        # XXX fix me
        res = condor.submit_dag(TestcondoTestcondorr.get_dag_file(), TestCondor.test_vargs, TestCondor.test_schedd, cmd_args=[])

